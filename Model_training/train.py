# -*- coding: utf-8 -*-
"""facial.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1slcEiIWKEFYhC0bIaYT3pz3MUalms-wH
"""

import zipfile
zipref=zipfile.ZipFile("/content/Student Behavior Detection.v3i.folder.zip","r")
zipref.extractall()
zipref.close()

import tensorflow as tf
from keras.preprocessing import image_dataset_from_directory



import numpy as np
from torchvision.datasets import ImageFolder
from torchvision import transforms
from torch.utils.data import DataLoader
from transformers import  ViTForImageClassification, ViTConfig, ViTFeatureExtractor,Trainer, TrainingArguments
import torch
import torch.nn as nn
from torch.optim import AdamW
from tqdm import tqdm
from pathlib import Path
from PIL import Image

from transformers import ViTFeatureExtractor, ViTForImageClassification, ViTConfig
from torchvision import transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
import torch
from torch import nn
from torch.optim import AdamW
from tqdm import tqdm
import copy

# Feature extractor and transform
feature_extractor = ViTFeatureExtractor.from_pretrained("Alpiyildo/vit-Facial-Expression-Recognition")
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)
])

# Datasets and dataloaders
train_dataset = ImageFolder("//content/train", transform=transform)
test_dataset = ImageFolder("/content/test", transform=transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)
val_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)

# Model setup
config = ViTConfig.from_pretrained("Alpiyildo/vit-Facial-Expression-Recognition")
config.num_labels = 4
model = ViTForImageClassification.from_pretrained(
     "Alpiyildo/vit-Facial-Expression-Recognition",
    config=config,
    ignore_mismatched_sizes=True
)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = AdamW(model.parameters(), lr=2e-5)

# Callback-like variables
best_val_acc = 0.0
best_model_wts = copy.deepcopy(model.state_dict())
early_stop_counter = 0
patience = 5  # Stop if val accuracy doesn't improve for 5 epochs

# Training loop
for epoch in range(50):
    model.train()
    total_loss = 0
    correct = 0
    total = 0

    for images, labels in tqdm(train_loader, desc=f"Epoch {epoch+1} - Training"):
        images, labels = images.to(device), labels.to(device)
        outputs = model(pixel_values=images)
        loss = criterion(outputs.logits, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        preds = outputs.logits.argmax(dim=1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

    train_acc = correct / total
    train_loss = total_loss / len(train_loader)

    # Validation
    model.eval()
    val_loss = 0
    val_correct = 0
    val_total = 0
    with torch.no_grad():
        for images, labels in tqdm(val_loader, desc=f"Epoch {epoch+1} - Validation"):
            images, labels = images.to(device), labels.to(device)
            outputs = model(pixel_values=images)
            loss = criterion(outputs.logits, labels)
            val_loss += loss.item()
            preds = outputs.logits.argmax(dim=1)
            val_correct += (preds == labels).sum().item()
            val_total += labels.size(0)

    val_acc = val_correct / val_total
    val_loss /= len(val_loader)

    print(f"[Epoch {epoch+1}] Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | "
          f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")

    # Save best model
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        best_model_wts = copy.deepcopy(model.state_dict())
        early_stop_counter = 0
        print("Best model updated.")
    else:
        early_stop_counter += 1
        print(f" Early stopping counter: {early_stop_counter}/{patience}")
        if early_stop_counter >= patience:
            print("Early stopping triggered.")
            break

# Load best model weights after training
model.load_state_dict(best_model_wts)

model.save_pretrained("/content/my_model")

torch.save(model.state_dict(), "/content/my_model.pth")

from transformers import AutoImageProcessor

processor = AutoImageProcessor.from_pretrained("Alpiyildo/vit-Facial-Expression-Recognition")
processor.save_pretrained("models_vi")

import os
from transformers import AutoModelForImageClassification, AutoImageProcessor

# Local model path
model_path = "models_vi"

# Your dataset path (change to 'train' or 'val' if needed)
dataset_path = "test"

# Extract sorted class names from folder names
class_names = sorted(entry for entry in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, entry)))
id2label = {i: name for i, name in enumerate(class_names)}
label2id = {name: i for i, name in id2label.items()}

print("Detected classes:", id2label)

# Load and update model
model = AutoModelForImageClassification.from_pretrained(model_path)
model.config.id2label = id2label
model.config.label2id = label2id
model.save_pretrained(model_path)  # Save the updated model

# Load processor too (in case needed)
processor = AutoImageProcessor.from_pretrained(model_path)

print("Model updated with class names and saved.")